import os
import time
import re
from urllib.parse import urljoin, urlparse
from selenium import webdriver
from bs4 import BeautifulSoup
from markdownify import markdownify as md
from tqdm import tqdm

BASE_URL = "https://docs.4gaboards.com"
START_PATH = "/docs/user-manual"
START_URL = urljoin(BASE_URL, START_PATH)

OUTPUT_DIR = "../../user_docs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Selenium è®¾ç½®
options = webdriver.ChromeOptions()
options.add_argument("--headless")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
driver = webdriver.Chrome(options=options)


def sanitize_filename(path: str) -> str:
    """å°† URL path è½¬æ¢ä¸ºå®‰å…¨çš„æ–‡ä»¶å"""
    slug = path.strip("/").split("/")[-1] or "index"
    slug = re.sub(r"[^\w\-]+", "-", slug)
    return slug + ".md"


def fetch_and_convert_to_markdown(url: str) -> tuple[str, str]:
    """è·å–é¡µé¢å†…å®¹å¹¶è½¬æ¢ä¸º markdown"""
    driver.get(url)
    time.sleep(2)
    soup = BeautifulSoup(driver.page_source, "lxml")

    article = soup.find("article")

    title_tag = article.find("h1")
    title = title_tag.text.strip() if title_tag else "Untitled"

    content_html = str(article)
    content_md = md(content_html)

    markdown = f"{content_md}"
    return sanitize_filename(urlparse(url).path), markdown


def extract_internal_doc_links(markdown: str) -> list:
    """ä» user-manual é¡µé¢æå–å­æ–‡æ¡£é“¾æ¥"""
    links = []
    base_path = urlparse(BASE_URL).path

    matches = matches = re.findall(r"\]\((/docs/[^)]+)\)", markdown)
    for match in matches:
        full_url = urljoin(BASE_URL, match)
        links.append(full_url)

    return list(set(links))  # å»é‡


def main():
    print(f"æ­£åœ¨æŠ“å–ä¸»é¡µé¢ï¼š{START_URL}")
    driver.get(START_URL)
    time.sleep(2)
    soup = BeautifulSoup(driver.page_source, "lxml")

    # ä¸»é¡µé¢ä¹Ÿä¿å­˜
    try:
        filename, markdown = fetch_and_convert_to_markdown(START_URL)
        filename = "For Users.md"

        # å¯¹æœ€é«˜å±‚çº§çš„ä¸»é¡µé¢æ·»åŠ è¯´æ˜
        markdown = "This is mainpage of For User documents\n\n" + markdown
        with open(os.path.join(OUTPUT_DIR, filename), "w", encoding="utf-8") as f:
            f.write(markdown)
    except Exception as e:
        print(f"âŒ ä¸»é¡µé¢æŠ“å–å¤±è´¥ï¼š{e}")

    # æŠ½å–å­é¡µé¢é“¾æ¥
    sub_links = extract_internal_doc_links(markdown)
    print(f"âœ… æ‰¾åˆ° {len(sub_links)} ä¸ªå­é“¾æ¥ï¼Œå¼€å§‹æŠ“å–...")

    for url in tqdm(sub_links):
        try:
            filename, markdown = fetch_and_convert_to_markdown(url)

            lines = markdown.splitlines()
            markdown = "\n".join(lines[3:])  # åˆ é™¤å‰ä¸¤è¡Œ

            # åˆ é™¤ "On this page" åŠå…¶ä»¥ä¸‹å†…å®¹ï¼ˆç›´åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜æˆ–æ®µè½ï¼‰
            markdown = re.sub(r"(?mi)^on this page\s*\n(?:[-*].*\n)*\n*", "", markdown)

            with open(os.path.join(OUTPUT_DIR, filename), "w", encoding="utf-8") as f:
                f.write(markdown)
        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥: {url}ï¼Œé”™è¯¯: {e}")

    print(f"\nğŸ‰ æ‰€æœ‰é¡µé¢å·²ä¿å­˜è‡³ {OUTPUT_DIR}/ æ–‡ä»¶å¤¹ã€‚")


if __name__ == "__main__":
    main()
    driver.quit()
